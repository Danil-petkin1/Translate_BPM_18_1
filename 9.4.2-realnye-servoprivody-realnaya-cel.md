# 9.4.2 Реальные сервоприводы, реальная цель

Если предположить, что все прошло хорошо при отслеживании вымышленной цели в предыдущем разделе, то теперь мы можем попробовать отследить реальную цель с помощью глубинной камеры, установленной на сервоприводах с функцией панорамирования. Вместо того, чтобы отслеживать конкретный тип объекта, например, лицо, мы будем использовать узел, который вычисляет центр тяжести \(COG\) ближайшего облака точек перед камерой. Мы использовали ту же самую технику в приложении "Человек-погонщик" в томе 1, которая позволила мобильному роботу, оборудованному камерой глубины, следить за ближайшим "каплями" перед камерой. 

Скрипт, который делает эту работу, называется nearest\_cloud.py в каталоге rbx2\_vision/nodes, и мы вкратце опишем его. Однако сначала попробуем.  
  
 Предположим, что у вас все еще есть запущенные из предыдущего раздела запускаемые файлы для подключения к вашим панорамным и наклонным сервоприводам. Если нет, запустите эти файлы сейчас.   
  
Далее, Ctrl-C из файла запуска pub3d\_target.launch, если он всё ещё запущен. Желтая сфера должна перестать двигаться в RViz.   
Далее, откройте узел OpenNI для вашей глубинной камеры:

```text
$ roslaunch rbx2_vision openni_node.launch
```

Теперь вызовите ближайший узел облака, используя соответствующий файл запуска:

```text
$ roslaunch rbx2_vision nearest_cloud.launch
```

Этот файл запустит фильтр `VoxelGrid` и два фильтра `PassThrough`, чтобы ограничить обработку облака точек ящиком перед камерой шириной 0,6 метра \(около фута с каждой стороны\), простирается наружу до 1,0 метра \(около 3 футов\) и проходит 0,3 метра \(около 1 фута\) под камерой и 0,15 метра \(6 дюймов\) над камерой. Это создает своего рода "фокус внимания" для робота, так что мы можем отслеживать объекты, которые находятся относительно близко к камере. Результирующее облако точек выводится на тему под названием `/cloud_filtered`.

Затем выходим из RViz, если он все еще работает, и снова запускаем его с помощью конфигурационного файла `track_pointcloud.rviz`:

```text
$ rosrun rviz rviz -d `rospack find
rbx2_vision`/config/track_pointcloud.rviz
```

тот файл конфигурации включает в себя дисплей `PointCloud2`, который подписан на тему `/cloud_filtered`. Теперь поместите руку или какой-нибудь объект перед камерой и вы должны увидеть соответствующее облако точек в `RViz`. Обратите внимание на то, как ваша рука или другой объект будет выглядеть и исчезать по мере того, как вы перемещаете его внутрь и нарушаете границы, определенные фильтрами `PassThrough`.   
Наконец, если узел головного трекера еще не запущен, запустите его сейчас с симметричным аргументом, установленным в `false`:

```text
$ roslaunch rbx2_dynamixels head_tracker.launch sim:=false
```

После небольшой задержки головка для панорамирования и наклона должна начать отслеживать ближайший объект перед камерой. Имейте в виду, что как Kinect, так и Xtion Pro не могут видеть объекты на глубине ближе примерно 0,5 метра \(чуть менее 2 футов\). Также помните, что файл `nearest_cloud.launch` отфильтровывает точки, находящиеся на расстоянии более 1 метра. \(Вы можете запустить `rqt_reconfigure` и настроить параметры фильтров `VoxelGrid` и `PassThrough` на лету, или изменить их в файле запуска\). Если вы стоите перед камерой внутри блока фильтров и двигаетесь влево или вправо, камера должна отслеживать ваше движение. Если вы отодвинете свое тело назад на расстояние более 1 метра от камеры, а затем вытяните руку в коробку фильтра, то голова и камера должны отслеживать движение вашей руки. Если вы сомневаетесь в том, что камера обнаруживает, убедитесь, что вы можете наблюдать `RViz` на экране вашего компьютера, так что вы должны отслеживать изображение облака точек.

