# 9. Отслеживание головы робота в 3D

В томе 1 мы узнали, как запрограммировать узел слежения за головой, который перемещает камеру для слежения за лицом или другой целью, опубликованной в теме `/roi`, используя тип сообщения `RegionOfInterest.` В этих случаях цель представлялась в виде сообщения ROS `RegionOfInterest`, определяющего прямоугольную область, обычно вписывающуюся в плоскость обзора камеры, окружающей отслеживаемый объект. Тем не менее, реальный мир является трехмерным, и, поскольку глубинные камеры, такие как Kinect, относительно недороги, нет особых причин не воспользоваться преимуществами 3-го измерения. Более того, сама ROS была построена с нуля, чтобы работать во всех трех измерениях. В частности, библиотека `tf` не испытывает проблем с преобразованием данных 3-х мерного датчика из одной референцной рамки в другую, что избавляет от лишних затрат на вычисления того, как пространство объекта позиционируется относительно робота. \(Если только Вы не особенно хорошо умеете умножать кватернионы в голове.\) 

![](.gitbook/assets/image%20%281%29.png)

В этой главе мы добавим глубинную информацию к проблеме визуального слежения за объектами, чтобы вместо 2D сообщения `RegionOfInterest` для представления объекта, мы использовали 3D сообщение `PoseStamped`. Для отслеживания головы нам не понадобятся компоненты ориентации этого типа сообщений, поэтому мы сможем обойтись без более простого сообщения с `PoseStamped`; однако, поскольку ориентация цели будет важна, когда дело касается захвата объекта в главе "Навигация руки и MoveIt", мы также будем использовать более общее сообщение с `PoseStamped` здесь. Сообщение с `PoseStamped` может представлять собой расположение лица или цветного объекта, но также может отслеживать другие точки в пространстве, например, расположение захвата на руке робота, которые могут даже не быть в поле зрения камеры. \(Напомним, что мы всегда знаем расположение захвата или других частей робота относительно камеры по URDF модели робота и `robot_state_publisher`\). Наша задача состоит в том, чтобы спроецировать эту 3D позу на плоскость камеры, так что мы знаем, как переместить камеру к цели. Перед тем, как посмотреть на код, мы запустим пару примеров с использованием нового головного трекера. Но сначала давайте создадим узел, который будет публиковать вымышленную движущуюся 3D точку, которую мы сможем использовать для тестирования нашего отслеживания.

